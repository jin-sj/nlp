{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import subprocess\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from koreantools.korean_parser import KoreanParser\n",
    "\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for dirName, subdirList, fileList in os.walk(root_dir):\n",
    "    for fname in fileList:\n",
    "        if '.json' in fname:\n",
    "            get_raw_text(os.path.join(dirName, fname), fname.split('.')[0])\n",
    "            i += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_raw_text(file_path, fname):\n",
    "    with open(file_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    transcript = data['original_human_transcript']\n",
    "    root = ET.fromstring(transcript)\n",
    "    texts = []\n",
    "    for element in root:\n",
    "        for subelement in element:\n",
    "            texts.append(subelement.text)\n",
    "    \n",
    "    dirname = os.path.dirname(file_path)\n",
    "    #file1 = open(os.path.join(dirname, \"text.txt\"), \"a\")\n",
    "    fname = fname + '.txt'\n",
    "    file1 = open(os.path.join('/Users/sjjin/workspace/koreantools/koreantools/tests/corpus', fname), \"a\")\n",
    "\n",
    "    for text in texts:\n",
    "        file1.write(text+\"\\n\")\n",
    "    file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abb'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ab\"+\"b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'카르페 디엠,지금 이 순간을 잡아라 메멘토 모리,죽음을 기억하라 아모르 파티,운명을 사랑하라 로마 제국의 언어이자 유럽의 많은언어를 탄생하게 했던 언어 라틴어입니다. 수 천년 전의 라틴어가 지금까지도많은 사람들로부터 인용되고 있습니다. 이는 라틴어 격언이 담고 있는인생의 진리가 지금의 현대인에게도 큰 울림을주고 있기 때문입니다. 로마의 공동 묘지 입구에는 이러한문장이 새겨져 있습니다. Hodie mihi, cras tibi. 오늘은 나에게 내일은 너에게. 오늘은 비록 나에게 죽음이찾아왔지만 당신에게도 죽음이 찾아갈 수 있으니 자신의 죽음을 한 번 생각해보라는 말입니다. 라틴어 격언은 삶과 죽음을한 문장으로 축약합니다. 라틴어 수업을 진행한한동일 교수의 강의에 수백명이 몰렸던 이유가 이것일 겁니다. 서강대에서 열린초급, 중급 라틴어 수업은 첫 학기 24명의 수강생으로 시작했지만 다음 학기부터 200명이 넘는 수강생, 다른 대학의 학생과 일반 청강생까지찾아오는 강의가 되었습니다. 예상 밖의 인기에 놀란 교수는 나중에이유를 알게 되었습니다. 학생들은 단순한 라틴어 수업이 아닌 인생에 대한 종합적인 인문 수업을들으러 온 것이었습니다. 오늘은 그 강의를 엮은 책라틴어 수업에서 제게 큰 여운을 주었던 라틴어 격언세 가지를 소개하고자 합니다. 1.격렬함 뒤에 오는 건 Post coitum omne animal triste est 무슨 뜻일까요? 모든 동물은 우울하다. 짝짓기 후에 모든 동물은 짝짓기 후에 우울하다입니다. 이 문장 내면의 의미는 다음과 같습니다. 열정적으로 고대하던 순간이격렬하게 지나고 나면 인간은 더 큰 무언가를 놓치고말았다는 허무함을 느낀다 인간은 욕망합니다. 목표를 추구합니다. 하지만 그렇게 갈망하던 목표를달성한 순간 인간이 느끼는 감정은만족이 아니라 우울함입니다. 열정적으로 기대한 순간이격렬하게 지나간 뒤 가슴 속에 남아있는 녀석은 허무함입니다. 그런데 저자는그 우울을 느껴보라고 말합니다. 그 우울함을 느끼는 위치까지 올라가 이 감정의 정체가 무엇인지알게되는 것을 권유합니다. 한 분야에서 최선을 다해노력하지 않은 사람이 그거? 별거 아니야 라고 말한다면 우리는 그 말에서진정성을 느낄 수 없습니다. 성공과 실패를 해보지 않은 사람이그것에 대해 논한다면 그 말에는 무게가 실리지 않습니다. 돈, 권력, 쾌락을 쫓다가그 화려함을 얻었을 때 우리는 그부질없음을 느낄 수 있습니다. 그 뒤에야 우리는 진정으로 자신이원하는 것 자신을 행복하게 하는 것을발견할 수 있습니다. 노력 뒤의 성공,그 뒤에 오는 우울함 속에서 삶의 의미를 찾을 수 있기를 바랍니다. 2.상처를 살펴보기 Vulnerant omnes ultima necat. 모든 사람은 상처를 주다가결국엔 죽는다. 씁쓸한 말입니다. 세상의 아름다움, 사람 사이의 따듯함만 느끼다 가기에도 짧은 생이지만 인간은 서로에게 상처를 주다가결국엔 죽습니다. 저자 또한 그 상처를 누군가로부터받습니다. 저자는 상처 준 상대에게화를 내고 분노하다가 문득 생각을 합니다. 그가 과연 나에게 상처를 주었나 저자는 말합니다. 마음을 한 겹 벗겨보니그는 제게 상처를 준 것이 아니었습니다. 그의 행동과 말을 통해서 제 안의약함과 부족함을 확인했기 때문에 제가 아팠던 거예요. 저는 상처 받은 게 아니었습니다. 제 안에 감추고 싶은 어떤 것이타인에게 확인되었던 것 뿐이죠. 결국 상처는 스스로 준다는 말입니다. 자신에게 약함과 부족함이 없다면 상처를 주는 상대의 말은 그저공기 속으로 사라지는 공허입니다. 하지만 누구나 약함이 존재하며 상대의 공격으로 자신의 약함과마주하면서 상처가 생기는 것입니다. 물론 원하지 않는 것을 들춰내는상대에게도 잘못이 있지만 저자는 상처를 통해서 마주하기두려운 자신의 약점을 인식하고 바꾸어나가는 계기로 활용하라고말합니다. 3. 배움의 이유 Non scholae, sed vitae discimus 우리는 학교가 아니라 인생을 위해서공부한다. 학문의 목적이 어떤 것에 대해 아는 것자체가 되어서는 안 됩니다. 앎을 통해 인간과 삶에 대한 더나은 관점을 가지는 것이어야 합니다. 따듯한 가슴 없이 머리에만 엄청난 시간과열정을 들인 사람이 있습니다. 그 사람의 공부는 흉기가 되어다른 사람을 찌릅니다. 저자는 말합니다. 배웠다고 하는 사람들이 자기 주머니를 불리는 일에는발군의 실력을 발휘하면서도 다른 사람들이 착취당하며사회구조적으로 계속 가난할 수 밖에 없는 시스템에는 무신경해요. 저자는 강의를 듣는 수강생에게말합니다. 공부한 사람의 포부가 좀 더 크고넓은 차원의 것이었으면 좋겠다고, 그게 배운 사람과 배우지 않은 사람의 차이점일 거라고 말이죠. 지금까지 책 라틴어 수업을 통해 라틴어 격언 세 가지를 살펴보았습니다. 진리에 대한 격언은 이렇게 지금까지도 우리에게 많은 의미를 주고 있습니다. 시간이 되시면 한 번쯤고대의 격언을 통해 인생을 돌아보는 것 어떨까요. 책그림이었습니다.감사합니다.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = re.sub(\"[\\(\\[<].*?[\\)\\]>(>\\.)]\", \"\", texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'카르페 디엠,\\n지금 이 순간을 잡아라 메멘토 모리,\\n죽음을 기억하라 아모르 파티,\\n운명을 사랑하라 로마 제국의 언어이자 유럽의 많은\\n언어를 탄생하게 했던 언어 라틴어입니다. 수 천년 전의 라틴어가 지금까지도\\n많은 사람들로부터 인용되고 있습니다. 이는 라틴어 격언이 담고 있는\\n인생의 진리가 지금의 현대인에게도 큰 울림을\\n주고 있기 때문입니다. 로마의 공동 묘지 입구에는 이러한\\n문장이 새겨져 있습니다. Hodie mihi, cras tibi. 오늘은 나에게 내일은 너에게. 오늘은 비록 나에게 죽음이\\n찾아왔지만 당신에게도 죽음이 찾아갈 수 있으니 자신의 죽음을 한 번 생각해보라는 말입니다. 라틴어 격언은 삶과 죽음을\\n한 문장으로 축약합니다. 라틴어 수업을 진행한\\n한동일 교수의 강의에 수백명이 몰렸던 이유가 이것일 겁니다. 서강대에서 열린\\n초급, 중급 라틴어 수업은 첫 학기 24명의 수강생으로 시작했지만 다음 학기부터 200명이 넘는 수강생, 다른 대학의 학생과 일반 청강생까지\\n찾아오는 강의가 되었습니다. 예상 밖의 인기에 놀란 교수는 나중에\\n이유를 알게 되었습니다. 학생들은 단순한 라틴어 수업이 아닌 인생에 대한 종합적인 인문 수업을\\n들으러 온 것이었습니다. 오늘은 그 강의를 엮은 책\\n라틴어 수업에서 제게 큰 여운을 주었던 라틴어 격언\\n세 가지를 소개하고자 합니다. 1.격렬함 뒤에 오는 건 Post coitum omne animal triste est 무슨 뜻일까요? 모든 동물은 우울하다. 짝짓기 후에 모든 동물은 짝짓기 후에 우울하다\\n입니다. 이 문장 내면의 의미는 다음과 같습니다. 열정적으로 고대하던 순간이\\n격렬하게 지나고 나면 인간은 더 큰 무언가를 놓치고\\n말았다는 허무함을 느낀다 인간은 욕망합니다. 목표를 추구합니다. 하지만 그렇게 갈망하던 목표를\\n달성한 순간 인간이 느끼는 감정은\\n만족이 아니라 우울함입니다. 열정적으로 기대한 순간이\\n격렬하게 지나간 뒤 가슴 속에 남아있는 녀석은 허무함입니다. 그런데 저자는\\n그 우울을 느껴보라고 말합니다. 그 우울함을 느끼는 위치까지 올라가 이 감정의 정체가 무엇인지\\n알게되는 것을 권유합니다. 한 분야에서 최선을 다해\\n노력하지 않은 사람이 그거? 별거 아니야 라고 말한다면 우리는 그 말에서\\n진정성을 느낄 수 없습니다. 성공과 실패를 해보지 않은 사람이\\n그것에 대해 논한다면 그 말에는 무게가 실리지 않습니다. 돈, 권력, 쾌락을 쫓다가\\n그 화려함을 얻었을 때 우리는 그부질없음을 느낄 수 있습니다. 그 뒤에야 우리는 진정으로 자신이\\n원하는 것 자신을 행복하게 하는 것을\\n발견할 수 있습니다. 노력 뒤의 성공,\\n그 뒤에 오는 우울함 속에서 삶의 의미를 찾을 수 있기를 바랍니다. 2.상처를 살펴보기 Vulnerant omnes ultima necat. 모든 사람은 상처를 주다가\\n결국엔 죽는다. 씁쓸한 말입니다. 세상의 아름다움, \\n사람 사이의 따듯함만 느끼다 가기에도 짧은 생이지만 인간은 서로에게 상처를 주다가\\n결국엔 죽습니다. 저자 또한 그 상처를 누군가로부터\\n받습니다. 저자는 상처 준 상대에게\\n화를 내고 분노하다가 문득 생각을 합니다. 그가 과연 나에게 상처를 주었나 저자는 말합니다. 마음을 한 겹 벗겨보니\\n그는 제게 상처를 준 것이 아니었습니다. 그의 행동과 말을 통해서 제 안의\\n약함과 부족함을 확인했기 때문에 제가 아팠던 거예요. 저는 상처 받은 게 아니었습니다. 제 안에 감추고 싶은 어떤 것이\\n타인에게 확인되었던 것 뿐이죠. 결국 상처는 스스로 준다는 말입니다. 자신에게 약함과 부족함이 없다면 상처를 주는 상대의 말은 그저\\n공기 속으로 사라지는 공허입니다. 하지만 누구나 약함이 존재하며 상대의 공격으로 자신의 약함과\\n마주하면서 상처가 생기는 것입니다. 물론 원하지 않는 것을 들춰내는\\n상대에게도 잘못이 있지만 저자는 상처를 통해서 마주하기\\n두려운 자신의 약점을 인식하고 바꾸어나가는 계기로 활용하라고\\n말합니다. 3. 배움의 이유 Non scholae, sed vitae discimus 우리는 학교가 아니라 인생을 위해서\\n공부한다. 학문의 목적이 어떤 것에 대해 아는 것\\n자체가 되어서는 안 됩니다. 앎을 통해 인간과 삶에 대한 더\\n나은 관점을 가지는 것이어야 합니다. 따듯한 가슴 없이 머리에만 엄청난 시간과\\n열정을 들인 사람이 있습니다. 그 사람의 공부는 흉기가 되어\\n다른 사람을 찌릅니다. 저자는 말합니다. 배웠다고 하는 사람들이 자기 주머니를 불리는 일에는\\n발군의 실력을 발휘하면서도 다른 사람들이 착취당하며\\n사회구조적으로 계속 가난할 수 밖에 없는 \\n시스템에는 무신경해요. 저자는 강의를 듣는 수강생에게\\n말합니다. 공부한 사람의 포부가 좀 더 크고\\n넓은 차원의 것이었으면 좋겠다고, 그게 배운 사람과 배우지 않은 사람의 차이점일 거라고 말이죠. 지금까지 책 라틴어 수업을 통해 라틴어 격언 세 가지를 살펴보았습니다. 진리에 대한 격언은 이렇게 지금까지도 우리에게 많은 의미를 주고 있습니다. 시간이 되시면 한 번쯤\\n고대의 격언을 통해 인생을 돌아보는 것 어떨까요. 책그림이었습니다.\\n감사합니다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "#pos = okt.pos('[indiscernible] 김태원 아내 이현주 딸 결혼 최근 김태원이 다시 예능에서 활발한 활동을 하고 있습니다. 어트케')\n",
    "pos = okt.pos('김태원 아내 이현주 딸 결혼 최근 김태원이 다시 예능에서 활발한 활동을 하고 있습니다. 어트케')\n",
    "\n",
    "#okt.pos(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('김태원', 'Noun')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아', 'Exclamation'),\n",
       " ('어트케', 'Noun'),\n",
       " ('어떡해', 'Adjective'),\n",
       " ('ㅇ', 'KoreanParticle'),\n",
       " ('ㅓㅗ', 'KoreanParticle'),\n",
       " ('쇽', 'Noun')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.pos(\"아 어트케 어떡해 ㅇ ㅓㅗ 쇽\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"data/1CrMRS8tGoI/test.txt\", \"a\") \n",
    "file1.write(clean)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'김태원 아내 이현주 딸 결혼 최근 김태원이 다시 예능에서 활발한 활동을 하고 있습니다. 어트케'\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "text = \"\\'김태원 아내 이현주 딸 결혼 최근 김태원이 다시 예능에서 활발한 활동을 하고 있습니다. 어트케\\'\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jin/workspace/nlp/data/1CrMRS8tGoI'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname('/home/jin/workspace/nlp/data/1CrMRS8tGoI/text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_text(path, text):\n",
    "    text_file = os.path.join(path, 'text.txt')\n",
    "    file1 = open(text_file, 'a')\n",
    "    file1.write(text)\n",
    "    file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_errors(text_path):\n",
    "    #cmd = \"cat %s | hanspell-cli 2>&1 > /dev/null | grep '→'\" % text_path\n",
    "    cmd = \"cat %s | hanspell-cli 2>&1 > /dev/null | grep \\'→\\'\" % text_path\n",
    "    print(cmd)\n",
    "    #output = subprocess.check_output(cmd.split())\n",
    "    #return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(json_path):\n",
    "    data = None\n",
    "    with open(json_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    transcript = data['original_human_transcript']\n",
    "    root = ET.fromstring(transcript)\n",
    "    texts = []\n",
    "    for element in root:\n",
    "        for subelement in element:\n",
    "            texts.append(subelement.text)\n",
    "    texts = ' '.join(texts)\n",
    "    texts.replace('\\n', '')\n",
    "    clean = re.sub(\"[\\(\\[<].*?[\\)\\]>(>\\.)]\", \"\", texts)\n",
    "    write_text(os.path.dirname(json_path), clean)\n",
    "    output = fix_errors(os.path.join(os.path.dirname(json_path), 'text.txt'))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat /home/jin/workspace/nlp/data/1CrMRS8tGoI/text.txt | hanspell-cli 2>&1 > /dev/null | grep '→'\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['cat', '/home/jin/workspace/nlp/data/1CrMRS8tGoI/text.txt', '|', 'hanspell-cli', '2>&1', '>', '/dev/null', '|', 'grep', \"'→'\"]' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-97259ae70331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mjson_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/jin/workspace/nlp/data/1CrMRS8tGoI/1CrMRS8tGoI.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-46ffe849560f>\u001b[0m in \u001b[0;36mclean_data\u001b[0;34m(json_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[\\(\\[<].*?[\\)\\]>(>\\.)]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mwrite_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-28a68f3cdc47>\u001b[0m in \u001b[0;36mfix_errors\u001b[0;34m(text_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cat %s | hanspell-cli 2>&1 > /dev/null | grep \\'→\\'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtext_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 411\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 512\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['cat', '/home/jin/workspace/nlp/data/1CrMRS8tGoI/text.txt', '|', 'hanspell-cli', '2>&1', '>', '/dev/null', '|', 'grep', \"'→'\"]' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "json_path = '/home/jin/workspace/nlp/data/1CrMRS8tGoI/1CrMRS8tGoI.json'\n",
    "clean_data(json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/9beach/hanspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('뷛대', 'Noun')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt = Okt()\n",
    "okt.pos(\"뷛대\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kor_representation(number):\n",
    "    mapping = {\n",
    "        1: '일',\n",
    "        2: '이',\n",
    "        3: '삼',\n",
    "        4: '사',\n",
    "        5: '오',\n",
    "        6: '육',\n",
    "        7: '칠',\n",
    "        8: '팔',\n",
    "        9: '구'\n",
    "        10: '십'\n",
    "        100: '백'\n",
    "    }\n",
    "    return mapping(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_kor(text, literal=False):\n",
    "    if not text.isnumeric():\n",
    "        return text\n",
    "    result = ''\n",
    "    if literal:\n",
    "        for number in text:\n",
    "            result += kor_representation(number)\n",
    "    #else:\n",
    "        \n",
    "    return result\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meeting\n",
    "1. Fix spacing / spelling errors\n",
    "    - Use hanspell, https://github.com/9beach/hanspell , (two options, Daum vs Busan University)\n",
    "    - Could we use for big data? Might be limited in # of api calls\n",
    "    - Use https://github.com/spellcheck-ko/hunspell-dict-ko/ have not explored yet\n",
    "2. Morpheme / part of speech\n",
    "    - konlpy, open source\n",
    "    - Could use for spacing, 3 engines available\n",
    "    - Can't use for spell check\n",
    "    - Not perfect, runtime varies\n",
    "3. Change numbers to kor text\n",
    "    - 121 -> 일이일 or 일백이십일 or 백이십일\n",
    "    - 369 -> 삼륙구 or 삼육구\n",
    "4. Any test/dummy data that is more similar to hotpepper transcription?\n",
    "5. Keep note of punctuation/markers\n",
    "    - After having fixed the issues\n",
    "    - Char index & type of punctuation/marker\n",
    "    - Could use the part of speech from konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of tokens \n",
    "returns new list, clean version same size as original list\n",
    "\n",
    "returns 2 lists\n",
    "    1. list of token of words\n",
    "    2. mapping to original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input: 카르페 디엠,\n",
    "output: 카르페 디엠\n",
    "input: 카르페 디엠,\n",
    "[카르페, 디엠, ',']\n",
    "[0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '아모르 파티, 운명을 사랑하라'\n",
    "a = ['아모르', '파티', '운명을', '사랑하라']\n",
    "b = ['', ' ', ',', ' ', '', ' ', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a), len(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edge cases:\n",
    "'너를.사랑한다' # Fix this issue before stripping punctuation\n",
    "'너를... 사랑한다'\n",
    "'그래서 너 ...'\n",
    "'그래서 너 --'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns \n",
    "def strip_punctuation(text):\n",
    "    original = text.split(' ')\n",
    "    stripped_tokens = []\n",
    "    punctuation_mapping = []\n",
    "    for token in original:\n",
    "        #if token[0] in string.punctuation:\n",
    "        if token[-1] in string.punctuation:\n",
    "            stripped_tokens.append(token[:-1])\n",
    "            punctuation_mapping.append(token[-1])\n",
    "        else:\n",
    "            stripped_tokens.append(token)\n",
    "            punctuation_mapping.append('')\n",
    "        punctuation_mapping.append(' ')\n",
    "    return stripped_tokens, punctuation_mapping[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['카르페', '디엠']\n",
      "['', ' ', ',']\n"
     ]
    }
   ],
   "source": [
    "text = '카르페 디엠,'\n",
    "stripped_tokens, mapping = strip_punctuation(text)\n",
    "print(stripped_tokens)\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아모르', '파티', '운명을', '사랑하라']\n",
      "['', ' ', ',', ' ', '', ' ', '']\n"
     ]
    }
   ],
   "source": [
    "text = '아모르 파티, 운명을 사랑하라'\n",
    "stripped_tokens, mapping = strip_punctuation(text)\n",
    "print(stripped_tokens)\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['야', '너두', '영어', '할', '수', '있어', '왜', '그냥', '그래', '바보야', '자신감을', '가져']\n",
      "['!', ' ', '', ' ', '', ' ', '', ' ', '', ' ', '.', ' ', '?', ' ', '', ' ', '.', ' ', ',', ' ', '', ' ', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '[inaudible] 야! 너두 영어 할 수 있어. 왜? 그냥 그래. 바보야, 자신감을 가져.'\n",
    "stripped_tokens, mapping = strip_punctuation(text)\n",
    "print(stripped_tokens)\n",
    "print(mapping)\n",
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_const =\\\n",
    "{\n",
    "  \"Adjective\": \"형용사\",\n",
    "  \"Adverb\": \"부사\",\n",
    "  \"Alpha\": \"알파벳\",\n",
    "  \"Conjunction\": \"접속사\",\n",
    "  \"Determiner\": \"관형사\",\n",
    "  \"Eomi\": \"어미\",\n",
    "  \"Exclamation\": \"감탄사\",\n",
    "  \"Foreign\": \"외국어, 한자 및 기타기호\",\n",
    "  \"Hashtag\": \"트위터 해쉬태그\",\n",
    "  \"Josa\": \"조사\",\n",
    "  \"KoreanParticle\": \"(ex: ㅋㅋ)\",\n",
    "  \"Noun\": \"명사\",\n",
    "  \"Number\": \"숫자\",\n",
    "  \"PreEomi\": \"선어말어미\",\n",
    "  \"Punctuation\": \"구두점\",\n",
    "  \"ScreenName\": \"트위터 아이디\",\n",
    "  \"Suffix\": \"접미사\",\n",
    "  \"Unknown\": \"미등록어\",\n",
    "  \"Verb\": \"동사\"\n",
    "}\n",
    "REMOVE = [\"Alpha\", \"Foregin\", \"KoreanParticle\"]\n",
    "CHECK = [\"Noun\", \"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김태원 Noun\n",
      "아내 Noun\n",
      "이현주 Noun\n",
      "딸 Noun\n",
      "결혼 Noun\n",
      "최근 Noun\n",
      "김태원 Noun\n",
      "이 Josa\n",
      "다시 Noun\n",
      "예능 Noun\n",
      "에서 Josa\n",
      "활발한 Adjective\n",
      "활동 Noun\n",
      "을 Josa\n",
      "하고 Verb\n",
      "있습니다 Adjective\n",
      ". Punctuation\n",
      "어트케 Noun\n"
     ]
    }
   ],
   "source": [
    "text = '김태원 아내 이현주 딸 결혼 최근 김태원이 다시 예능에서 활발한 활동을 하고 있습니다. 어트케'\n",
    "def fix_spelling_errors(text):\n",
    "    okt = Okt()\n",
    "    pos = okt.pos(text)\n",
    "    fixed = ''\n",
    "    for token, p in pos:\n",
    "        if p ==\n",
    "        print(token, p)\n",
    "fix_spelling_errors(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!GIHO\tsy\n",
      "\n",
      "\"\tsl\tsr\n",
      "\n",
      "$\tsu\n",
      "\n",
      "%\tsu\n",
      "\n",
      "'\tsl\tsr\n",
      "\n",
      "(\tsl\n",
      "\n",
      "(KS)\tsy\n",
      "\n",
      "(주)\tncn\n",
      "\n",
      "(주)대우\tnqq\n",
      "\n",
      ")\tsr\n",
      "\n",
      "*\tsy\n",
      "\n",
      ",\tsp\n",
      "\n",
      "-\tsd\n",
      "\n",
      "->\tsy\n",
      "\n",
      ".\tsf\tsy\n",
      "\n",
      "...\tse\n",
      "\n",
      "......\tse\n",
      "\n",
      "/\tsp\n",
      "\n",
      "007시리즈\tncn\n",
      "\n",
      "1.21\tnqq\n",
      "\n",
      "1.21사태\tnqq\n",
      "\n",
      "1.21청와대기습기도사건\tnqq\n",
      "\n",
      "1.22\tnqq\n",
      "\n",
      "1.22공동선언\tnqq\n",
      "\n",
      "1.22선언\tnqq\n",
      "\n",
      "1.22정계개편\tnqq\n",
      "\n",
      "1.22정재편\tnqq\n",
      "\n",
      "1.22합당\tnqq\n",
      "\n",
      "1.22합당선언\tnqq\n",
      "\n",
      "10.15선거\tnqq\n",
      "\n",
      "10.26\tnqq\n",
      "\n",
      "10.26사건\tnqq\n",
      "\n",
      "10.26사태\tnqq\n",
      "\n",
      "10.26시해사건\tnqq\n",
      "\n",
      "10.26정변\tnqq\n",
      "\n",
      "10.26쿠데타\tnqq\n",
      "\n",
      "100가지\tncn\n",
      "\n",
      "10대\tncn\n",
      "\n",
      "10대가수\tncn\n",
      "\n",
      "10대그룹\tncn\n",
      "\n",
      "10대뉴스\tncn\n",
      "\n",
      "10대청소년\tncn\n",
      "\n",
      "10부제\tncn\n",
      "\n",
      "10부제운행\tncn\n",
      "\n",
      "10세기\tnqq\n",
      "\n",
      "10월유신\tnqq\n",
      "\n",
      "10월혁명\tncn\n",
      "\n",
      "10종경기\tncn\n",
      "\n",
      "10차선\tncn\n",
      "\n",
      "114\tncn\n",
      "\n",
      "119\tncn\n",
      "\n",
      "11세기\tnqq\n",
      "\n",
      "12.12\tncn\n",
      "\n",
      "12.12군사반란\tnqq\n",
      "\n",
      "12.12군사쿠데타\tnqq\n",
      "\n",
      "12.12반란\tnqq\n",
      "\n",
      "12.12사건\tnqq\n",
      "\n",
      "12.12사태\tncn\n",
      "\n",
      "12.12쿠데타\tnqq\n",
      "\n",
      "129센터\tncn\n",
      "\n",
      "129응급센터\tncn\n",
      "\n",
      "12세기\tnqq\n",
      "\n",
      "12지\tncn\n",
      "\n",
      "13대대선\tnqq\n",
      "\n",
      "13대총선\tnqq\n",
      "\n",
      "13대총선거\tnqq\n",
      "\n",
      "13세기\tncn\n",
      "\n",
      "14대\tncn\n",
      "\n",
      "14대국회의원선거\tnqq\n",
      "\n",
      "14대대선\tnqq\n",
      "\n",
      "14대대통령선거\tnqq\n",
      "\n",
      "14대총선\tnqq\n",
      "\n",
      "14대총선거\tnqq\n",
      "\n",
      "14세\tncn\n",
      "\n",
      "14세기\tnqq\n",
      "\n",
      "14총선\tnqq\n",
      "\n",
      "15대\tncn\n",
      "\n",
      "15세기\tnqq\n",
      "\n",
      "16강\tncn\n",
      "\n",
      "16강전\tncn\n",
      "\n",
      "16세\tncn\n",
      "\n",
      "16세기\tnqq\n",
      "\n",
      "16주기\tncn\n",
      "\n",
      "17세기\tncn\n",
      "\n",
      "18세기\tnqq\n",
      "\n",
      "1937년\tncn\n",
      "\n",
      "19세기\tncn\n",
      "\n",
      "1tv\tncn\n",
      "\n",
      "1가구1주택\tncn\n",
      "\n",
      "1관왕\tncn\n",
      "\n",
      "1당독재\tncn\n",
      "\n",
      "1등서기관\tncn\n",
      "\n",
      "1등석\tncn\n",
      "\n",
      "1루수\tncn\n",
      "\n",
      "1부리그\tncn\n",
      "\n",
      "1분기\tncn\n",
      "\n",
      "1세\tncn\n",
      "\n",
      "1세기\tnqq\n",
      "\n",
      "1원화\tncn\n",
      "\n",
      "1인당\tncn\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_raw_dict(file_path):\n",
    "    i = 0\n",
    "    with open(file_path) as txt_file:\n",
    "        line = txt_file.readline()\n",
    "        while line and i < 100:\n",
    "            line = txt_file.readline()\n",
    "            print(line)\n",
    "            i += 1\n",
    "get_raw_dict('/Users/sjjin/workspace/koreantools/koreantools/data/dic_system.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 12), match='[SPEAKER 1:]'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.match('\\[SPEAKER \\d\\:]', '[SPEAKER 1:]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match('\\[SPEAKER \\d\\:]', 'ddd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '[SPEAKER 1:] 야! 너두 영어 할 [unsure] 수 있어. 왜? 그냥 그래. 바보야, 자신감을 가져 ...'\n",
    "expected_stripped_text = ['야', '너두', '영어', '할', '수', '있어', '왜', '그냥', '그래', '바보야', '자신감을', '가져']\n",
    "expected_mapping = ['[SPEAKER 1:] ',\n",
    "                    '!', \n",
    "                    ' ',\n",
    "                    '', \n",
    "                    ' ',\n",
    "                    '', \n",
    "                    ' ',\n",
    "                    '', \n",
    "                    ' [unsure] ',\n",
    "                    '', \n",
    "                    ' ',\n",
    "                    '.', \n",
    "                    ' ',\n",
    "                    '?', \n",
    "                    ' ',\n",
    "                    '', \n",
    "                    ' ',\n",
    "                    '.', \n",
    "                    ' ',\n",
    "                    ',', \n",
    "                    ' ',\n",
    "                    '', \n",
    "                    ' ', # could be ' ...' and remove the next element\n",
    "                    '...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['야', '너두', '영어', '할', '수', '있어', '왜', '그냥', '그래', '바보야', '자신감을', '가져'],\n",
       " ['[SPEAKER 1:] ',\n",
       "  '!',\n",
       "  ' ',\n",
       "  '',\n",
       "  ' ',\n",
       "  '',\n",
       "  ' ',\n",
       "  '',\n",
       "  ' ',\n",
       "  ' [unsure] ',\n",
       "  '',\n",
       "  ' ',\n",
       "  '.',\n",
       "  ' ',\n",
       "  '?',\n",
       "  ' ',\n",
       "  '',\n",
       "  ' ',\n",
       "  '.',\n",
       "  ' ',\n",
       "  ',',\n",
       "  ' ',\n",
       "  '',\n",
       "  ' ',\n",
       "  ''])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from koreantools.korean_parser import KoreanParser\n",
    "\n",
    "text = '[SPEAKER 1:] 야! 너두 영어 할 [unsure] 수 있어. 왜? 그냥 그래. 바보야, 자신감을 가져 ...'\n",
    "\n",
    "kor = KoreanParser()\n",
    "\n",
    "expected_mapping = ['[SPEAKER 1:] ',\n",
    "                    '!', \n",
    "                    ' ',\n",
    "                    '', \n",
    "                    ' ',\n",
    "                    '', \n",
    "                    ' ',\n",
    "                    '', \n",
    "                    ' [unsure] ',\n",
    "                    '', \n",
    "                    ' ',\n",
    "                    '.', \n",
    "                    ' ',\n",
    "                    '?', \n",
    "                    ' ',\n",
    "                    '', \n",
    "                    ' ',\n",
    "                    '.', \n",
    "                    ' ',\n",
    "                    ',', \n",
    "                    ' ',\n",
    "                    '', \n",
    "                    ' ', # could be ' ...' and remove the next element\n",
    "                    '...']\n",
    "kor.penning(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 12), match='[SPEAKER 1:]'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(\"(\\[.+?\\])?([\\.{3}\\-{2}])?\")\n",
    "pattern.search(text)\n",
    "#re.search(\"(\\[.+?\\])?(\\.{3})?(\\-{2})?\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[SPEAKER 1:]', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('[unsure]', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '', ''),\n",
       " ('', '...', ''),\n",
       " ('', '', '')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"(\\[.+?\\])?(\\.{3})?(\\-{2})?\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "text = '야! 너두 영어 할 수 있어. 왜? 그냥 그래. 바보야, 자신감을 가져.'\n",
    "expected_mapping = ['', '! ', ' ', ' ', ' ', ' ', '. ', '? ', ' ', '. ', ', ', ' ', '.']\n",
    "print(len(text.split()))\n",
    "print(len(expected_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "kor = KoreanParser()\n",
    "split_text, mapping = kor.penning(text)\n",
    "print(len(split_text))\n",
    "print(len(mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['야', '너두', '영어', '할', '수', '있어', '왜', '그냥', '그래', '바보야', '자신감을', '가져']\n",
      "['', '!', ' ', ' ', ' ', ' ', '.', '?', ' ', '.', ',', ' ', '.']\n"
     ]
    }
   ],
   "source": [
    "kor = KoreanParser()\n",
    "split_text, mapping = kor.penning(text)\n",
    "print(split_text)\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
